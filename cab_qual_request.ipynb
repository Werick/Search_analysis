{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6113fd8e",
   "metadata": {},
   "source": [
    "   i.      CAB-LA Patient IDI cohort: Per Table 1 (below), we will systematically select ~n=30 patients per each region (South West Uganda and Kenya) (total for both countries 40 < ~n < 72; due to time and resource limitations, a smaller sample may be collected during this study), with samples within region to be balanced proportional to overall intervention enrolment by:\n",
    "\n",
    "    Original trials (OPD, ANC/PNC, VHT);\n",
    "    Gender; and\n",
    "    Community.\n",
    "Please note, we would to interview some of those who opted for the injection but then after receiving one or two injections have decided not to continue with them. However, we would not want to interview more than a total of 10 - 15 of those no longer taking CAB-LA. Please indicate those persons in the list (perhaps with an *).\n",
    "\n",
    "Table 1 (below)\n",
    "·  N= 12-20 outpatient clinic clients (n=3-5 per 4 communities)\n",
    "\n",
    " \n",
    "\n",
    "·  N= 16-20 Antenatal and postnatal clients (n= 2-3 per antenatal and postnatal group per 4 communities)\n",
    "\n",
    " \n",
    "\n",
    "·  N= 12-20 men and women recruited from VHT clients (n= 3-5 per 4 communities, gender-balanced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d1c76e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyodbc\n",
    "import json\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "import datetime;\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a8897187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DB connection\n",
    "def connect_to_mysql():\n",
    "    # Load connection details from JSON file\n",
    "    with open('connection_details.json', 'r') as file:\n",
    "        connection_details = json.load(file)\n",
    "        mysql_credentials=connection_details['mysql']\n",
    "    \n",
    "    # Establish connection to MySQL database\n",
    "    try:\n",
    "        connection = create_engine(\"mysql+pymysql://{user}:{pw}@{host}/{db}\"\n",
    "                .format(host=mysql_credentials['host'],\n",
    "                user=mysql_credentials['user'],\n",
    "                pw=mysql_credentials['password'],\n",
    "                db=mysql_credentials['cab_database']))\n",
    "        \n",
    "        print(\"Successfully connected to MySQL database\")\n",
    "        return connection        \n",
    "        \n",
    "        # Close the database connection\n",
    "        connection.close()\n",
    "        print(\"Connection closed\")\n",
    "        return df_partcipant\n",
    "    except:\n",
    "        print(\"Failed to connect to MySQL database: {}\")\n",
    "        return false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "88e50f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to MySQL database\n",
      "(265, 26)\n",
      "ANC LIST\n"
     ]
    }
   ],
   "source": [
    "#Get connection to the db\n",
    "conn = connect_to_mysql()\n",
    "\n",
    "# Pull data\n",
    "sql = \"\"\"\n",
    "    SELECT\n",
    "        *\n",
    "    FROM        \n",
    "        d_participant;\n",
    "        \"\"\"\n",
    "        \n",
    "df = pd.read_sql(sql, conn)\n",
    "df = df[['subjid', 'participant_id', 'trial', 'clinic',\n",
    "       'country', 'study_arm', 'screened', 'screened_met', 'consented',\n",
    "       'enrolled', 'baseline_visit', 'cab_screen_date', 'cab_enr_date', 'cab_baseline_date', 'age',\n",
    "       'age_group', 'sex']]\n",
    "\n",
    "\n",
    "\n",
    "# get List of participants who have had a cab injection\n",
    "sql = \"\"\"\n",
    "    SELECT\n",
    "        subjid, vdate,cab_vweek, screen_cab_met, injection_received\n",
    "    FROM \n",
    "        schedc_cab_baseline\n",
    "    WHERE\n",
    "       screen_cab_met = 1 AND injection_received = 1; \n",
    "    \"\"\"\n",
    "df_cab = pd.read_sql(sql, conn)\n",
    "\n",
    "sql = \"\"\"\n",
    "    SELECT\n",
    "        subjid, vdate,cab_vweek, screen_cab_met, injection_received, stop_cab\n",
    "    FROM \n",
    "        schedc_cab_followup; \n",
    "    \"\"\"\n",
    "df_cab_fu = pd.read_sql(sql, conn)\n",
    "df_cab_fu['vdate'] = pd.to_datetime(df_cab_fu['vdate'])\n",
    "df_cab_fu.sort_values('vdate', inplace=True, ascending=False)\n",
    "df_cab_fu.loc[df_cab_fu['screen_cab_met'] == 0, 'stop_cab'] = 1\n",
    "\n",
    "df_latest_cab_status = df_cab_fu.groupby('subjid').first().reset_index()\n",
    "\n",
    "# get those on who ever started cab only\n",
    "df_int = df[(df['study_arm'] == 'Int') & (df['enrolled'] == 1)]\n",
    "df_int = df_int.merge(df_cab, on = 'subjid', how = 'inner')\n",
    "df_int = df_int.merge(df_latest_cab_status, on = 'subjid', how = 'left')\n",
    "print(df_int.shape)\n",
    "\n",
    "# get individual trials\n",
    "df_anc = df_int[(df_int['trial'] == 'ANC')]\n",
    "df_opd = df_int[(df_int['trial'] == 'OPD')]\n",
    "df_vht = df_int[(df_int['trial'] == 'VHT/CHV')]\n",
    "\n",
    "# Get Sample some of those who opted for the injection but then after receiving one or two injections have decided not to continue with them.\n",
    "# Get those who are wk 24 since start of cab injection and have stopped injection\n",
    "\n",
    "# get max injections given\n",
    "summary_data = df_cab_fu.groupby(['subjid']).agg({'injection_received':[\n",
    "    ('injections', lambda x: np.where(x == 1, 1,0).sum()),\n",
    "    ('cab_vweek',lambda x: np.where(df_cab_fu['cab_vweek'] == 99, 0,df_cab_fu['cab_vweek']).max()),\n",
    "    ('stop_cab_vweek',lambda x: np.where(df_cab_fu['stop_cab'] == 1.0, df_cab_fu['cab_vweek'],99).min())\n",
    "]})\n",
    "# Reset the index to make  regular columns\n",
    "summary_data = summary_data.reset_index()\n",
    "\n",
    "# Rename the aggregated column for clarity\n",
    "summary_data.columns = ['subjid', 'n_injections', 'max_vweek','stop_cab_vweek']\n",
    "\n",
    "\n",
    "# add the baseline injection\n",
    "summary_data['n_injections_inc_baseline'] = summary_data['n_injections'] + 1\n",
    "# expected injections as at wk 24\n",
    "summary_data['expected_injections'] = 5\n",
    "df_stopped = df_cab_fu[df_cab_fu['stop_cab'] == 1]\n",
    "df_stopped_cab = summary_data[(summary_data['n_injections_inc_baseline']<=2) & (summary_data['subjid'].isin(df_stopped['subjid']))]\n",
    "\n",
    "df_stopped_cab = df_stopped_cab.merge(df_int[['subjid','trial','sex', 'clinic']], on = 'subjid', how = 'inner')\n",
    "\n",
    "# Get the sample\n",
    "# Define the stratification variables for OPD and VHT\n",
    "strata_columns = ['trial', 'clinic', 'sex']\n",
    "\n",
    "# Define the desired sample size\n",
    "sample_size = 1  # Adjust this according to your requirements\n",
    "\n",
    "# Perform stratified sampling\n",
    "stratified_sample = df_stopped_cab.groupby(strata_columns, as_index=False, group_keys=False).apply(lambda x: x.sample(n=sample_size, random_state=42))\n",
    "stratified_sample['ever_stopped_cab'] = 1\n",
    "# drop anyone who had stopped cab\n",
    "df_anc = df_anc[~df_anc['subjid'].isin(df_stopped_cab['subjid'])]\n",
    "df_opd = df_opd[~df_opd['subjid'].isin(df_stopped_cab['subjid'])]\n",
    "df_vht = df_vht[~df_vht['subjid'].isin(df_stopped_cab['subjid'])]\n",
    "\n",
    "# Define the desired sample size\n",
    "sample_size = 5  # Adjust this according to your requirements\n",
    "\n",
    "# Perform stratified sampling\n",
    "#stratified_sample = df_int.groupby(strata_columns, as_index=False, group_keys=False).apply(lambda x: x.sample(n=sample_size, random_state=42))\n",
    "\n",
    "sample_size = 4\n",
    "stratified_sample_anc = df_anc.groupby(['clinic'], as_index=False, group_keys=False).apply(lambda x: x.sample(n=sample_size, random_state=42))\n",
    "\n",
    "sample_size = 2\n",
    "\n",
    "stratified_sample_opd = df_opd.groupby(['clinic', 'sex'], as_index=False, group_keys=False).apply(lambda x: x.sample(n=sample_size, random_state=42))\n",
    "stratified_sample_vht = df_vht.groupby(['clinic', 'sex'], as_index=False, group_keys=False).apply(lambda x: x.sample(n=sample_size, random_state=42))\n",
    "\n",
    "stratified_sample_anc['ever_stopped_cab'] = 0\n",
    "stratified_sample_opd['ever_stopped_cab'] = 0\n",
    "stratified_sample_vht['ever_stopped_cab'] = 0\n",
    "\n",
    "\n",
    "include_vars = ['subjid','trial','clinic','sex','ever_stopped_cab']\n",
    "\n",
    "# Concatenate the DataFrames vertically (bind rows)\n",
    "df_out = pd.concat([stratified_sample_anc[include_vars], stratified_sample_opd[include_vars], stratified_sample_vht[include_vars], stratified_sample[include_vars]])\n",
    "\n",
    "\n",
    "# Reset the index\n",
    "df_out = df_out.reset_index(drop=True)\n",
    "\n",
    "df_out.sort_values('clinic', inplace=True, ascending=False)\n",
    "df_out\n",
    "\n",
    "# check if in ANC trial the the 3 participants were included\n",
    "#Postnatal vs antenatal (Anyone who signed pregnancy consent will be classified as antenatal)\n",
    "# There are only 3 Pregnancies reported in ANC Trial\n",
    "anc_antenatal = ['SP11005006', 'SP11007006', 'SP11004005']\n",
    "print('ANC LIST')\n",
    "df_out[df_out['subjid'].isin(anc_antenatal)]\n",
    "\n",
    "# print line list\n",
    "df_out.to_csv('qual_IDI_list.csv', encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "716e98e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to MySQL database\n"
     ]
    }
   ],
   "source": [
    "# Generate list of provider for IDI\n",
    "#Get connection to the db\n",
    "conn = connect_to_mysql()\n",
    "# Sample Providers\n",
    "sql = \"\"\"\n",
    "    SELECT\n",
    "        *\n",
    "    FROM \n",
    "        prvdr_mm_survey p\n",
    "    left outer Join meta m on m.run_uuid = p.run_uuid; \n",
    "    \"\"\"\n",
    "df_prvdr = pd.read_sql(sql, conn)\n",
    "df_prvdr['subjid'] = df_prvdr['subjid'].astype(int)\n",
    "df = df_prvdr.copy()\n",
    "\n",
    "# get list of providers from excel\n",
    "df_prv_list = pd.read_excel(\"CAB LA Provider ids- to ew 3rd-7-23.xlsx\", sheet_name='Sheet1')\n",
    "df_prv_list['subjid'] = df_prv_list['Intervierwe ID']\n",
    "\n",
    "# Change IDs from to avoid duplicates for specific IDs - cloud db\n",
    "df_prvdr.loc[(df_prvdr['subjid'] == 4) & (df_prvdr['tablet'] == 'Tablet15'), 'subjid'] = 104 #uganda\n",
    "df_prvdr.loc[(df_prvdr['subjid'] == 7) & (df_prvdr['tablet'] == '532'), 'subjid'] = 107 #Kenya\n",
    "df_prvdr.loc[(df_prvdr['subjid'] == 12) & (df_prvdr['tablet'] == '501'), 'subjid'] = 112 #Kenya\n",
    "df_prvdr.loc[(df_prvdr['subjid'] == 17) & (df_prvdr['tablet'] == '525'), 'subjid'] = 117 #Kenya\n",
    "#df_prvdr.loc[(df_prvdr['subjid'] == 76) & (df_prvdr['tablet'] == 'Tablet15'), 'subjid'] = 176 #Uganda\n",
    "\n",
    "\n",
    "# Change IDs from to avoid duplicates for specific IDs - excel list\n",
    "df_prv_list.loc[(df_prv_list['subjid'] == 4) & (df_prv_list['clinic_name'] == 'BUSHENYI'), 'subjid'] = 104 #uganda\n",
    "df_prv_list.loc[(df_prv_list['subjid'] == 7) & (df_prv_list['clinic_name'] == 'Sena'), 'subjid'] = 107 #Kenya\n",
    "df_prv_list.loc[(df_prv_list['subjid'] == 12) & (df_prv_list['clinic_name'] == 'Magunga'), 'subjid'] = 112 #Kenya\n",
    "df_prv_list.loc[(df_prv_list['subjid'] == 17) & (df_prv_list['clinic_name'] == 'Oyani'), 'subjid'] = 117 #Kenya\n",
    "#df_prv_list.loc[(df_prv_list['subjid'] == 76) & (df_prv_list['clinic_name'] == 'Tablet15'), 'subjid'] = 176 #Uganda\n",
    "\n",
    "\n",
    "df_prvdr = df_prvdr.merge(df_prv_list, on = 'subjid', how = 'left')\n",
    "\n",
    "# drop missing or not linked IDs\n",
    "df_missing_id  = df_prvdr[df_prvdr['Study'].isna()]['subjid']\n",
    "df_prvdr = df_prvdr[~df_prvdr['subjid'].isin(df_missing_id)]\n",
    "\n",
    "df_out_provider = df_prvdr[['subjid', 'Study', 'study_visit', 'Country', 'Name', 'Gender', 'Conduct CAB-LA Procedures?', 'clinic_name']]\n",
    "\n",
    "df_out_prvdr = df_out_provider.groupby('subjid').first().reset_index()\n",
    "#drop youth and and HTN Linkage\n",
    "df_out_prvdr = df_out_prvdr[~df_out_prvdr['Study'].isin(['Youth', 'HTN Linkage'])]\n",
    "\n",
    "\n",
    "# drop RA\n",
    "df_out_prvdr_oth = df_out_prvdr[~df_out_prvdr['subjid'].isin([107,41, 13])]\n",
    "\n",
    "df_out_prvdr_ogongo_sibuoche = df_out_prvdr_oth[df_out_prvdr_oth['clinic_name'].isin(['Sibuoche', 'Ogongo', 'ITOJO'])]\n",
    "df_out_prvdr_oth = df_out_prvdr_oth[~df_out_prvdr_oth['subjid'].isin(df_out_prvdr_ogongo_sibuoche['subjid'])]\n",
    "\n",
    "sample_size = 2\n",
    "stratified_sample_prvdr = df_out_prvdr_oth.groupby(['clinic_name'], as_index=False, group_keys=False).apply(lambda x: x.sample(n=sample_size, random_state=150))\n",
    "# Add Ogongo and Sibouche VHT Providers\n",
    "stratified_sample_prvdr = pd.concat([stratified_sample_prvdr, df_out_prvdr_ogongo_sibuoche])\n",
    "\n",
    "stratified_sample_prvdr.to_csv('qual_IDI_list_providers.csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
